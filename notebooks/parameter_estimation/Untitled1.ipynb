{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Import librairies\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import collections\n",
    "from importlib import reload\n",
    "\n",
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda, Layer, Add, Multiply, Reshape, Flatten, BatchNormalization\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Input, Dense, Dropout, MaxPool2D, Flatten,  Reshape, UpSampling2D, Cropping2D, Conv2DTranspose, PReLU, Concatenate, Lambda, BatchNormalization, concatenate, LeakyReLU\n",
    "\n",
    "tfd = tfp.distributions\n",
    "\n",
    "sys.path.insert(0,'../../scripts/tools_for_VAE/')\n",
    "import tools_for_VAE.layers as layers\n",
    "from tools_for_VAE import utils, vae_functions, generator, model\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Parameters\n",
    "nb_of_bands = 6\n",
    "batch_size = 100 \n",
    "\n",
    "input_shape = (64, 64, nb_of_bands)\n",
    "hidden_dim = 256\n",
    "latent_dim = 32\n",
    "final_dim = 9\n",
    "filters = [32, 64]#, 128]#, 256]#, 512]\n",
    "kernels = [3,3]#,3]#,3]#,3]\n",
    "\n",
    "conv_activation = None\n",
    "dense_activation = None\n",
    "\n",
    "steps_per_epoch = 32\n",
    "validation_steps = 8\n",
    "\n",
    "bands = [4,5,6,7,8,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BatchGenerator] total_sample_size =  100000\n",
      "[BatchGenerator] len(list_of_samples) =  10\n",
      "[BatchGenerator] total_sample_size =  20000\n",
      "[BatchGenerator] len(list_of_samples) =  2\n",
      "[BatchGenerator] total_sample_size =  10000\n",
      "[BatchGenerator] len(list_of_samples) =  1\n"
     ]
    }
   ],
   "source": [
    "# With generator\n",
    "images_dir = '/sps/lsst/users/barcelin/data/TFP/GalSim_COSMOS/blended_galaxies/random/'\n",
    "\n",
    "list_of_samples = [x for x in utils.listdir_fullpath(os.path.join(images_dir,'training')) if x.endswith('.npy')]\n",
    "list_of_samples_val = [x for x in utils.listdir_fullpath(os.path.join(images_dir,'validation')) if x.endswith('.npy')]\n",
    "list_of_samples_test = [x for x in utils.listdir_fullpath(os.path.join(images_dir,'test')) if x.endswith('.npy')]\n",
    "\n",
    "training_generator = generator.BatchGenerator_multi_galaxies(bands, list_of_samples, total_sample_size=None,\n",
    "                                    batch_size=batch_size, \n",
    "                                    trainval_or_test='training',\n",
    "                                    do_norm=False,\n",
    "                                    denorm = False,\n",
    "                                    list_of_weights_e=None)\n",
    "\n",
    "validation_generator = generator.BatchGenerator_multi_galaxies(bands, list_of_samples_val, total_sample_size=None,\n",
    "                                    batch_size=batch_size, \n",
    "                                    trainval_or_test='validation',\n",
    "                                    do_norm=False,\n",
    "                                    denorm = False,\n",
    "                                    list_of_weights_e=None)\n",
    "\n",
    "test_generator = generator.BatchGenerator_multi_galaxies(bands, list_of_samples_test, total_sample_size=None,\n",
    "                                    batch_size=batch_size, \n",
    "                                    trainval_or_test='test',\n",
    "                                    do_norm=False,\n",
    "                                    denorm = False,\n",
    "                                    list_of_weights_e=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 64, 64, 6)]       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 64, 64, 6)         24        \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 64, 64, 32)        1760      \n",
      "_________________________________________________________________\n",
      "p_re_lu (PReLU)              (None, 64, 64, 32)        131072    \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "p_re_lu_1 (PReLU)            (None, 32, 32, 32)        32768     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "p_re_lu_2 (PReLU)            (None, 32, 32, 64)        65536     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "p_re_lu_3 (PReLU)            (None, 16, 16, 64)        16384     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "p_re_lu_4 (PReLU)            (None, 16384)             16384     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 54)                884790    \n",
      "_________________________________________________________________\n",
      "p_re_lu_5 (PReLU)            (None, 54)                54        \n",
      "_________________________________________________________________\n",
      "multivariate_normal_tri_l (M ((None, 9), (None, 9))    0         \n",
      "=================================================================\n",
      "Total params: 1,213,444\n",
      "Trainable params: 1,213,432\n",
      "Non-trainable params: 12\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#### Model definition\n",
    "model_choice = 'wo_ls'\n",
    "# With latent space\n",
    "if model_choice == 'ls':\n",
    "    net = model.create_model(input_shape, latent_dim, hidden_dim, filters, kernels, final_dim, conv_activation=None, dense_activation=None)\n",
    "# Without latent space\n",
    "if model_choice == 'wo_ls': # create_model_wo_ls\n",
    "    net = model.create_model_wo_ls_multi(input_shape, latent_dim, hidden_dim, filters, kernels, final_dim, conv_activation=None, dense_activation=None)\n",
    "# Full probabilistic model\n",
    "if model_choice == 'full_prob':\n",
    "    net = model.create_model_full_prob(input_shape, latent_dim, hidden_dim, filters, kernels, final_dim, conv_activation=None, dense_activation=None)\n",
    "net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_fcn(x,y):\n",
    "    x[y==0]=0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Loss definition\n",
    "if model_choice == 'full_prob':\n",
    "    kl = sum(net.losses)\n",
    "    def loss(x, dists):\n",
    "        nll = -dists.log_prob(x)\n",
    "        print(nll)\n",
    "        kl = sum(net.losses)\n",
    "        print(kl)\n",
    "        return nll + kl, collections.namedtuple('loss','nll,kl')(nll, kl)\n",
    "    negative_log_likelihood = lambda x, rv_x: -rv_x.log_prob(x) + kl *(10/(batch_size*steps_per_epoch)-1)\n",
    "\n",
    "else:\n",
    "    def loss(x, dists):\n",
    "        mse = tf.keras.losses.MeanSquaredError()\n",
    "        loss = 0\n",
    "        for i in range(final_dim):\n",
    "            loss += mse(dists[:,i], x[:,i])\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Loss definition\n",
    "if model_choice == 'full_prob':\n",
    "    kl = sum(net.losses)\n",
    "    def loss(x, dists):\n",
    "        nll = -dists.log_prob(x)\n",
    "        print(nll)\n",
    "        kl = sum(net.losses)\n",
    "        print(kl)\n",
    "        return nll + kl, collections.namedtuple('loss','nll,kl')(nll, kl)\n",
    "    negative_log_likelihood = lambda x, rv_x: -rv_x.log_prob(x) + kl *(10/(batch_size*steps_per_epoch)-1)\n",
    "\n",
    "else:\n",
    "    def loss(x, dists):\n",
    "        mse = tf.keras.losses.MeanSquaredError()\n",
    "        loss = 0\n",
    "        \n",
    "        a = tf.numpy_function(numpy_fcn, [tf.ones([100], tf.float32), tf.convert_to_tensor(x[:,6])], tf.float32)\n",
    "        print(tf.math.squared_difference(dists[:,6], x[:,6]))\n",
    "        print(a*tf.math.squared_difference(dists[:,6], x[:,6]))\n",
    "        for i in range(final_dim):\n",
    "\n",
    "            a = tf.numpy_function(numpy_fcn, [tf.ones([100], tf.float32), tf.convert_to_tensor(x[:,i])], tf.float32)\n",
    "            loss += tf.reduce_mean(a*tf.math.squared_difference(dists.mean()[:,i], x[:,i]))#mse(a*dists[:,i], x[:,i])\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"loss_46/multivariate_normal_tri_l_loss/SquaredDifference:0\", shape=(None,), dtype=float32)\n",
      "Tensor(\"loss_46/multivariate_normal_tri_l_loss/mul:0\", dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "net.compile(optimizer=tf.optimizers.Adam(learning_rate=1e-3), \n",
    "              loss=loss , metrics = ['mse', 'acc'], experimental_run_tf_function=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_gen = training_generator.__getitem__(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 64, 64, 6), (100, 9))"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_gen[0].shape, output_gen[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = net(output_gen[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([100, 9])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=44919, shape=(100,), dtype=float32, numpy=\n",
       "array([ 120.44876  ,    0.       ,    0.       ,   67.16374  ,\n",
       "         67.31597  ,    7.269745 ,  601.2458   ,    0.       ,\n",
       "          0.       ,  160.15216  ,    0.       ,  581.25305  ,\n",
       "          0.       ,   24.038326 ,    9.825019 ,    0.       ,\n",
       "          0.       ,    0.       ,  330.3306   ,  851.8134   ,\n",
       "          0.       ,    0.       ,   23.520588 , 5736.814    ,\n",
       "          0.       ,    6.909252 ,  246.00133  ,    0.       ,\n",
       "          0.       ,  426.96735  ,    0.       ,    0.       ,\n",
       "          0.       ,    0.       ,    0.       ,    0.       ,\n",
       "          0.       ,    0.       ,    0.       ,   94.59921  ,\n",
       "          0.       ,    0.       ,    0.       ,    0.       ,\n",
       "          9.786209 ,    0.       ,    0.       ,    0.       ,\n",
       "          0.       ,    0.       ,    0.       ,  168.86195  ,\n",
       "          0.       ,  112.37687  ,    0.       ,  162.67291  ,\n",
       "          0.       ,    0.       ,    0.       ,    0.       ,\n",
       "        443.68344  ,    0.       ,   87.54528  ,    0.       ,\n",
       "          0.       ,   18.161377 ,   65.98454  ,  362.7559   ,\n",
       "          0.       ,    0.       ,   82.95971  ,  250.06697  ,\n",
       "          0.       ,    0.       ,    0.       ,    0.       ,\n",
       "        104.58891  ,    0.       ,    0.       ,    0.       ,\n",
       "         65.49178  ,    0.       ,    0.       ,  106.35344  ,\n",
       "          0.       ,   10.54059  ,    0.       ,    5.9140406,\n",
       "       1822.5536   ,  145.73102  , 2761.949    ,    0.       ,\n",
       "          0.       ,    0.       ,    0.       ,  123.64599  ,\n",
       "         70.00161  ,    0.       ,    0.       ,    0.       ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.mean()[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 2.43462685, 1.26475631,\n",
       "       0.        , 1.43136134, 2.82569438, 0.        , 1.97693151,\n",
       "       0.        , 2.85568027, 0.        , 1.93093921, 1.77665791,\n",
       "       0.        , 0.        , 0.        , 0.        , 2.32728051,\n",
       "       2.51568586, 0.        , 0.        , 2.1352878 , 1.58556154,\n",
       "       1.23519334, 0.        , 1.73603572, 0.        , 2.75683914,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 1.74726171, 2.91791675, 0.        ,\n",
       "       1.83240431, 1.29506644, 0.        , 2.09693051, 2.37737249,\n",
       "       2.24221799, 1.90922475, 2.35461801, 0.        , 1.53732181,\n",
       "       2.09935186, 2.32600093, 0.        , 0.        , 0.        ,\n",
       "       2.91625688, 2.62304023, 0.        , 1.33493704, 0.        ,\n",
       "       2.41319223, 3.04255937, 1.65124787, 2.72552843, 3.042251  ,\n",
       "       2.07789342, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 1.9231402 , 0.        , 0.        , 2.0441599 ,\n",
       "       0.        , 0.        , 1.66414922, 2.73782209, 1.89878308,\n",
       "       0.        , 1.89010909, 1.74410697, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 2.79846711,\n",
       "       0.        , 1.89116463, 0.        , 2.5149078 , 0.        ,\n",
       "       2.00179857, 0.        , 2.80884042, 0.        , 1.29185326])"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_gen[1][:,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[6.5288500e+05 2.4356442e+05 8.2501977e+04 4.7720441e+04 3.4274356e+05\n",
      " 2.4173436e+04 5.1109754e+04 4.0243895e+04 1.1962211e+05 1.9114895e+04\n",
      " 1.0651352e+04 1.4422552e+05 1.5970730e+06 3.7528266e+04 2.1144260e+04\n",
      " 9.4929938e+04 3.1274797e+03 5.4318110e+03 3.4009834e+05 8.0458828e+03\n",
      " 8.6189825e+05 4.0413305e+04 1.1973628e+04 1.1912888e+07 2.3656178e+04\n",
      " 6.9168281e+04 1.6230645e+05 1.8816910e+06 6.5254326e+03 8.0992175e+05\n",
      " 1.7984181e+05 2.9581103e+05 4.8329683e+03 1.6380754e+03 6.3961812e+03\n",
      " 4.9972550e+05 2.8814347e+05 3.4299992e+04 3.2536538e+05 1.6131282e+06\n",
      " 1.5158527e+04 2.4438803e+05 3.0948794e+05 1.0747566e+08 5.0286160e+02\n",
      " 2.8312520e+04 3.8941431e+05 1.2186572e+06 1.6060526e+04 1.8528217e+04\n",
      " 7.5254883e+04 1.4467570e+06 1.3621053e+05 2.1014911e+05 1.5024848e+05\n",
      " 9.9081523e+03 8.8324617e+04 4.2051394e+05 2.2406331e+05 1.1802981e+04\n",
      " 4.6693336e+04 1.5040711e+05 4.8465850e+05 1.0620540e+06 6.0701135e+06\n",
      " 5.4144614e+03 2.8304303e+05 3.2500341e+05 1.4180814e+05 8.0734870e+06\n",
      " 1.0088494e+04 9.9379980e+03 1.0221236e+04 4.7264425e+06 2.4461366e+05\n",
      " 4.1278414e+04 2.4541045e+05 4.2103297e+05 7.2589263e+03 4.5715637e+04\n",
      " 6.7218408e+02 2.2285578e+06 7.7706175e+05 3.1637041e+05 1.6801046e+03\n",
      " 1.2686014e+03 1.2671640e+05 1.3606874e+04 7.1462112e+05 2.5861176e+04\n",
      " 2.5714332e+07 2.6806153e+05 3.5428275e+05 2.6328540e+06 6.8637398e+04\n",
      " 2.4885622e+02 6.1789444e+01 2.9060784e+05 6.7949331e+05 5.7115319e+05], shape=(100,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.0000000e+00 0.0000000e+00 0.0000000e+00 4.7720441e+04 3.4274356e+05\n",
      " 0.0000000e+00 5.1109754e+04 4.0243895e+04 0.0000000e+00 1.9114895e+04\n",
      " 0.0000000e+00 1.4422552e+05 0.0000000e+00 3.7528266e+04 2.1144260e+04\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 8.0458828e+03\n",
      " 8.6189825e+05 0.0000000e+00 0.0000000e+00 1.1912888e+07 2.3656178e+04\n",
      " 6.9168281e+04 0.0000000e+00 1.8816910e+06 0.0000000e+00 8.0992175e+05\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 3.4299992e+04 3.2536538e+05 0.0000000e+00\n",
      " 1.5158527e+04 2.4438803e+05 0.0000000e+00 1.0747566e+08 5.0286160e+02\n",
      " 2.8312520e+04 3.8941431e+05 1.2186572e+06 0.0000000e+00 1.8528217e+04\n",
      " 7.5254883e+04 1.4467570e+06 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 9.9081523e+03 8.8324617e+04 0.0000000e+00 2.2406331e+05 0.0000000e+00\n",
      " 4.6693336e+04 1.5040711e+05 4.8465850e+05 1.0620540e+06 6.0701135e+06\n",
      " 5.4144614e+03 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 9.9379980e+03 0.0000000e+00 0.0000000e+00 2.4461366e+05\n",
      " 0.0000000e+00 0.0000000e+00 4.2103297e+05 7.2589263e+03 4.5715637e+04\n",
      " 0.0000000e+00 2.2285578e+06 7.7706175e+05 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.5861176e+04\n",
      " 0.0000000e+00 2.6806153e+05 0.0000000e+00 2.6328540e+06 0.0000000e+00\n",
      " 2.4885622e+02 0.0000000e+00 2.9060784e+05 0.0000000e+00 5.7115319e+05], shape=(100,), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=45227, shape=(), dtype=float32, numpy=2003321.5>"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(output_gen[1], out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(156237.890625, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "loss = mse(out[:,0], output_gen[1][:,0])\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=40486, shape=(), dtype=float32, numpy=-0.41115904>"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[:,0][0]-output_gen[1][:,0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.53119999, 0.        , 0.63150001,\n",
       "       0.62110001, 0.65170002, 0.73640001, 0.        , 0.65499997,\n",
       "       0.38839999, 0.        , 0.        , 1.12880003, 0.85460001,\n",
       "       1.17840004, 0.76550001, 0.        , 0.92610002, 0.23010001,\n",
       "       1.08340001, 3.2434001 , 2.3355999 , 0.        , 2.17070007,\n",
       "       0.78320003, 2.45079994, 0.        , 0.        , 2.4066    ,\n",
       "       0.5887    , 1.29910004, 0.        , 0.        , 1.53429997,\n",
       "       0.        , 1.1832    , 0.        , 1.25989997, 0.41929999,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.96359998,\n",
       "       0.4163    , 0.        , 0.41240001, 1.23010004, 2.12709999,\n",
       "       1.71819997, 0.8071    , 1.68219995, 0.97939998, 0.        ,\n",
       "       0.37099999, 1.83340001, 0.        , 0.        , 0.26800001,\n",
       "       4.71869993, 0.48359999, 0.65219998, 2.66700006, 0.73390001,\n",
       "       0.        , 0.361     , 0.20469999, 0.28749999, 2.27929997,\n",
       "       0.1913    , 0.92989981, 0.        , 1.77400005, 0.        ,\n",
       "       0.50150001, 0.        , 0.        , 0.        , 0.62800002,\n",
       "       0.81199998, 0.        , 0.72589999, 0.        , 1.06219995,\n",
       "       0.        , 0.47979999, 1.14289999, 0.99690002, 0.        ,\n",
       "       0.43959999, 0.74339998, 0.35780001, 0.        , 0.41569999,\n",
       "       0.56120002, 0.38839999, 0.        , 0.53780001, 0.        ])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_gen[1][:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "a = np.ones((100))\n",
    "a[output_gen[1][:,5]==0]=0\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 1.31980002, 1.23020005, 1.46389997, 0.54040003,\n",
       "       1.96379995, 0.        , 0.        , 0.30849999, 3.53970003,\n",
       "       0.        , 0.51370001, 0.        , 0.42320001, 0.47909999,\n",
       "       1.08420002, 0.44980001, 0.        , 1.24800003, 1.25090003,\n",
       "       0.53320003, 0.74150002, 0.65789998, 0.95920002, 0.745     ,\n",
       "       0.        , 1.09080005, 1.69120002, 0.        , 1.28269994,\n",
       "       1.13750005, 0.65649998, 0.76800001, 0.37349999, 1.36670005,\n",
       "       0.        , 0.        , 1.17700005, 0.54769999, 0.5072    ,\n",
       "       0.        , 0.43900001, 0.        , 1.12380004, 0.42629999,\n",
       "       0.        , 1.34019995, 0.99860001, 0.        , 0.96310002,\n",
       "       0.59170002, 3.01169991, 0.3114    , 0.3572    , 0.        ,\n",
       "       0.1389    , 1.102     , 2.05940008, 0.        , 1.03069997,\n",
       "       0.56870002, 1.60959995, 0.58939999, 0.        , 0.        ,\n",
       "       0.86900002, 0.67180002, 0.2062    , 0.55070001, 0.3312    ,\n",
       "       0.74070001, 0.67739999, 0.68830001, 0.        , 0.        ,\n",
       "       0.        , 1.7385    , 0.        , 0.33219999, 1.50139999,\n",
       "       0.32519999, 0.        , 0.0723    , 0.        , 0.60299999,\n",
       "       0.        , 1.85010004, 2.45860004, 0.        , 0.60039997,\n",
       "       0.        , 0.        , 0.60039997, 0.65509999, 2.3678    ,\n",
       "       0.        , 0.76889998, 0.94059998, 0.4303    , 1.77110004])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a*output_gen[1][:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
       "       0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
       "       1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
       "       0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a*np.ones((100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=790, shape=(100,), dtype=float32, numpy=\n",
       "array([ 3.69066772e+01,  3.39415710e+02,  3.44805725e+02,  7.50777359e+01,\n",
       "        5.78050346e+01, -2.82469415e-03, -4.88606602e-01,  9.35387497e+01,\n",
       "       -2.03814068e+01,  2.44932938e+02,  1.76271744e+02, -8.89910161e-01,\n",
       "        6.75783992e-01,  3.50118011e-01,  1.49429749e+03,  5.35632253e-01,\n",
       "        3.32552834e+01,  4.03296700e+01,  1.02944695e+02,  5.04831135e-01,\n",
       "       -1.44285830e-02,  1.28350675e+00,  1.28119504e+00, -3.63215820e+02,\n",
       "        2.41852097e+02, -4.92380738e-01,  1.45497522e+01,  5.07986816e+02,\n",
       "       -3.04148737e-02, -3.35347652e-02, -3.01782131e-01, -1.78311970e-02,\n",
       "        2.52956040e-02,  3.17429474e+02, -3.86724383e-01,  5.63173866e+01,\n",
       "       -1.07196423e+03,  3.63836974e-01,  1.03067088e+00, -3.73538047e-01,\n",
       "        1.42455762e+03,  3.00773804e+02,  4.80793266e+01,  1.38414764e+02,\n",
       "       -7.20186949e-01, -2.84404665e-01,  3.77850056e-01,  9.37060318e+01,\n",
       "        1.97219391e+02, -1.56357346e+02,  4.30592918e+01,  3.35444856e+00,\n",
       "       -8.02983704e+02,  2.80458679e+02, -1.07229435e+00,  8.27561855e-01,\n",
       "        8.27009106e+00, -4.58685681e-02,  8.80502625e+01, -1.40011799e+00,\n",
       "        6.03970222e+01,  2.81095104e+01,  4.50347573e-01, -5.89570701e-01,\n",
       "        1.86039108e+02, -7.58669436e-01,  2.07533646e+02, -4.49052467e+01,\n",
       "        6.29429970e+01, -4.10944672e+02,  3.59274811e+02,  4.42659836e+01,\n",
       "        1.30858301e+03, -7.91053343e+00, -1.95579731e+00, -7.25464582e-01,\n",
       "       -1.68119385e+02,  1.53577100e+03, -3.84257197e-01,  3.37128639e-02,\n",
       "        4.68797569e+01,  3.68898659e+01,  8.83909424e+02, -7.37328339e+01,\n",
       "        4.52966392e-01,  2.84147766e+02,  5.67294061e-01,  3.39400500e-01,\n",
       "        4.77765083e-01, -1.62422771e+01,  6.08406677e+01, -6.78870056e+02,\n",
       "        6.75653458e+00, -3.76764832e+02,  4.23903942e-01,  2.03934431e-01,\n",
       "        5.91824150e+00,  6.50087433e+01,  1.11165939e+02,  1.46612844e+01],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loading_path = '/sps/lsst/users/barcelin/TFP/weights/blended_multi_3/loss/'\n",
    "latest = tf.train.latest_checkpoint(loading_path)\n",
    "net.load_weights(latest)\n",
    "\n",
    "\n",
    "\n",
    "# Callbacks\n",
    "saving_path = '/sps/lsst/users/barcelin/TFP/weights/blended_multi_3/'\n",
    "checkpointer_mse = tf.keras.callbacks.ModelCheckpoint(filepath=saving_path+'mse/weights_noisy_v4.{epoch:02d}-{val_mse:.2f}.ckpt', monitor='val_mse', verbose=1, save_best_only=True,save_weights_only=True, mode='min', period=1)\n",
    "checkpointer_loss = tf.keras.callbacks.ModelCheckpoint(filepath=saving_path+'loss/weights_noisy_v4.{epoch:02d}-{val_loss:.2f}.ckpt', monitor='val_loss', verbose=1, save_best_only=True,save_weights_only=True, mode='min', period=1)\n",
    "checkpointer_acc = tf.keras.callbacks.ModelCheckpoint(filepath=saving_path+'acc/weights_noisy_v4.{epoch:02d}-{val_acc:.2f}.ckpt', monitor='val_acc', verbose=1, save_best_only=True,save_weights_only=True, mode='max', period=1)\n",
    "\n",
    "callbacks = [checkpointer_mse, checkpointer_loss, checkpointer_acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Train the network\n",
    "hist = net.fit_generator(training_generator, epochs=200, # training\n",
    "          steps_per_epoch=steps_per_epoch,#128\n",
    "          verbose=1,\n",
    "          shuffle=True,\n",
    "          validation_data=validation_generator, # validation\n",
    "          validation_steps=validation_steps,#16\n",
    "          callbacks= callbacks,\n",
    "          workers=0,#4 \n",
    "          use_multiprocessing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saving_path = '/sps/lsst/users/barcelin/TFP/weights/blended_multi_3/'\n",
    "net.save_weights(saving_path+'cp-{epoch:04d}.ckpt')\n",
    "# 2 galaxies dans /weights/blended_multi/\n",
    "\n",
    "\n",
    "## Plots\n",
    "loading_path = '/sps/lsst/users/barcelin/TFP/weights/blended_multi_3/loss/'\n",
    "latest = tf.train.latest_checkpoint(loading_path)\n",
    "net.load_weights(latest)\n",
    "\n",
    "\n",
    "test = test_generator.__getitem__(2)\n",
    "\n",
    "training_data = test[0]\n",
    "training_labels = test[1]\n",
    "out = net(training_data)\n",
    "\n",
    "fig = plt.figure()\n",
    "sns.distplot(out.mean().numpy()[:,0], bins = 20)\n",
    "sns.distplot(training_labels[:,0], bins = 20)\n",
    "fig.savefig('test_distrib_e1.png')\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "sns.distplot(out.mean().numpy()[:,1], bins = 20)\n",
    "sns.distplot(training_labels[:,1], bins = 20)\n",
    "fig.savefig('test_distrib_e2.png')\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "sns.distplot(out.mean().numpy()[:,2], bins = 20)\n",
    "sns.distplot(training_labels[:,2], bins = 20)\n",
    "fig.savefig('test_distrib_z.png')\n",
    "\n",
    "fig = plt.figure()\n",
    "sns.distplot(out.mean().numpy()[:,3], bins = 20)\n",
    "sns.distplot(training_labels[:,3], bins = 20)\n",
    "fig.savefig('test_distrib_e1_2.png')\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "sns.distplot(out.mean().numpy()[:,4], bins = 20)\n",
    "sns.distplot(training_labels[:,4], bins = 20)\n",
    "fig.savefig('test_distrib_e2_2.png')\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "sns.distplot(out.mean().numpy()[:,5], bins = 20)\n",
    "sns.distplot(training_labels[:,5], bins = 20)\n",
    "fig.savefig('test_distrib_z_2.png')\n",
    "\n",
    "fig = plt.figure()\n",
    "sns.distplot(out.mean().numpy()[:,6], bins = 20)\n",
    "sns.distplot(training_labels[:,6], bins = 20)\n",
    "fig.savefig('test_distrib_e1_3.png')\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "sns.distplot(out.mean().numpy()[:,7], bins = 20)\n",
    "sns.distplot(training_labels[:,7], bins = 20)\n",
    "fig.savefig('test_distrib_e2_3.png')\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "sns.distplot(out.mean().numpy()[:,8], bins = 20)\n",
    "sns.distplot(training_labels[:,8], bins = 20)\n",
    "fig.savefig('test_distrib_z_3.png')\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axes[0].plot(training_labels[:,0], out.mean().numpy()[:,0], '.', label = 'mean')\n",
    "axes[0].plot(training_labels[:,0], out.mean().numpy()[:,0]+ 2*out.stddev().numpy()[:,0], '+', label = 'mean + 2stddev')\n",
    "axes[0].plot(training_labels[:,0], out.mean().numpy()[:,0]- 2*out.stddev().numpy()[:,0], '+', label = 'mean - 2stddev')\n",
    "#x = np.linspace(-1,1)\n",
    "x = np.linspace(0,5)\n",
    "axes[0].plot(x, x)\n",
    "axes[0].legend()\n",
    "#axes[0].set_ylim(-1,1)\n",
    "axes[1].set_ylim(0,5)\n",
    "axes[0].set_title('$e1$')\n",
    "\n",
    "axes[1].plot(training_labels[:,1], out.mean().numpy()[:,1], '.', label = 'mean')\n",
    "axes[1].plot(training_labels[:,1], out.mean().numpy()[:,1]+ 2*out.stddev().numpy()[:,1], '+', label = 'mean + 2stddev')\n",
    "axes[1].plot(training_labels[:,1], out.mean().numpy()[:,1]- 2*out.stddev().numpy()[:,1], '+', label = 'mean - 2stddev')\n",
    "#x = np.linspace(-1,1)\n",
    "x = np.linspace(0,5)\n",
    "axes[1].plot(x, x)\n",
    "axes[1].legend()\n",
    "#axes[1].set_ylim(-1,1)\n",
    "axes[1].set_ylim(0,5)\n",
    "axes[1].set_title('$e2$')\n",
    "\n",
    "axes[2].plot(training_labels[:,2], out.mean().numpy()[:,2], '.', label = 'mean')\n",
    "axes[2].plot(training_labels[:,2], out.mean().numpy()[:,2]+ 2*out.stddev().numpy()[:,2], '+', label = 'mean + 2stddev')\n",
    "axes[2].plot(training_labels[:,2], out.mean().numpy()[:,2]- 2*out.stddev().numpy()[:,2], '+', label = 'mean - 2stddev')\n",
    "x = np.linspace(0,4)\n",
    "axes[2].plot(x, x)\n",
    "axes[2].legend()\n",
    "axes[2].set_ylim(-1,5.5)\n",
    "axes[2].set_title('$z$')\n",
    "\n",
    "fig.savefig('test_train.png')\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axes[0].plot(training_labels[:,3], out.mean().numpy()[:,3], '.', label = 'mean')\n",
    "axes[0].plot(training_labels[:,3], out.mean().numpy()[:,3]+ 2*out.stddev().numpy()[:,3], '+', label = 'mean + 2stddev')\n",
    "axes[0].plot(training_labels[:,3], out.mean().numpy()[:,3]- 2*out.stddev().numpy()[:,3], '+', label = 'mean - 2stddev')\n",
    "#x = np.linspace(-1,1)\n",
    "x = np.linspace(0,5)\n",
    "axes[0].plot(x, x)\n",
    "axes[0].legend()\n",
    "#axes[0].set_ylim(-1,1)\n",
    "axes[1].set_ylim(0,5)\n",
    "axes[0].set_title('$e1$')\n",
    "\n",
    "axes[1].plot(training_labels[:,4], out.mean().numpy()[:,4], '.', label = 'mean')\n",
    "axes[1].plot(training_labels[:,4], out.mean().numpy()[:,4]+ 2*out.stddev().numpy()[:,4], '+', label = 'mean + 2stddev')\n",
    "axes[1].plot(training_labels[:,4], out.mean().numpy()[:,4]- 2*out.stddev().numpy()[:,4], '+', label = 'mean - 2stddev')\n",
    "#x = np.linspace(-1,1)\n",
    "x = np.linspace(0,5)\n",
    "axes[1].plot(x, x)\n",
    "axes[1].legend()\n",
    "#axes[1].set_ylim(-1,1)\n",
    "axes[1].set_ylim(0,5)\n",
    "axes[1].set_title('$e2$')\n",
    "\n",
    "axes[2].plot(training_labels[:,5], out.mean().numpy()[:,5], '.', label = 'mean')\n",
    "axes[2].plot(training_labels[:,5], out.mean().numpy()[:,5]+ 2*out.stddev().numpy()[:,5], '+', label = 'mean + 2stddev')\n",
    "axes[2].plot(training_labels[:,5], out.mean().numpy()[:,5]- 2*out.stddev().numpy()[:,5], '+', label = 'mean - 2stddev')\n",
    "x = np.linspace(0,4)\n",
    "axes[2].plot(x, x)\n",
    "axes[2].legend()\n",
    "axes[2].set_ylim(-1,5.5)\n",
    "axes[2].set_title('$z$')\n",
    "fig.savefig('test_train_2.png')\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axes[0].plot(training_labels[:,6], out.mean().numpy()[:,6], '.', label = 'mean')\n",
    "axes[0].plot(training_labels[:,6], out.mean().numpy()[:,6]+ 2*out.stddev().numpy()[:,6], '+', label = 'mean + 2stddev')\n",
    "axes[0].plot(training_labels[:,6], out.mean().numpy()[:,6]- 2*out.stddev().numpy()[:,6], '+', label = 'mean - 2stddev')\n",
    "#x = np.linspace(-1,1)\n",
    "x = np.linspace(0,5)\n",
    "axes[0].plot(x, x)\n",
    "axes[0].legend()\n",
    "#axes[0].set_ylim(-1,1)\n",
    "axes[1].set_ylim(0,5)\n",
    "axes[0].set_title('$e1$')\n",
    "\n",
    "axes[1].plot(training_labels[:,7], out.mean().numpy()[:,7], '.', label = 'mean')\n",
    "axes[1].plot(training_labels[:,7], out.mean().numpy()[:,7]+ 2*out.stddev().numpy()[:,7], '+', label = 'mean + 2stddev')\n",
    "axes[1].plot(training_labels[:,7], out.mean().numpy()[:,7]- 2*out.stddev().numpy()[:,7], '+', label = 'mean - 2stddev')\n",
    "#x = np.linspace(-1,1)\n",
    "x = np.linspace(0,5)\n",
    "axes[1].plot(x, x)\n",
    "axes[1].legend()\n",
    "#axes[1].set_ylim(-1,1)\n",
    "axes[1].set_ylim(0,5)\n",
    "axes[1].set_title('$e2$')\n",
    "\n",
    "axes[2].plot(training_labels[:,8], out.mean().numpy()[:,8], '.', label = 'mean')\n",
    "axes[2].plot(training_labels[:,8], out.mean().numpy()[:,8]+ 2*out.stddev().numpy()[:,8], '+', label = 'mean + 2stddev')\n",
    "axes[2].plot(training_labels[:,8], out.mean().numpy()[:,8]- 2*out.stddev().numpy()[:,8], '+', label = 'mean - 2stddev')\n",
    "x = np.linspace(0,4)\n",
    "axes[2].plot(x, x)\n",
    "axes[2].legend()\n",
    "axes[2].set_ylim(-1,5.5)\n",
    "axes[2].set_title('$z$')\n",
    "fig.savefig('test_train_3.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
